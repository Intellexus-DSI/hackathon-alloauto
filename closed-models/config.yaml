# Model configuration
temperature: 0.3
few_shot: false
cot: false
seed: 42
model_name: "gemini-2.5-flash"
# model_name: "gemini-2.5-pro"
# model_name: "gpt-4o"
# model_name: "meta-llama/Llama-4-Scout-17B-16E-Instruct"
# max_tokens: 10000

# Data configuration  
data_dir: "../dataset/annotated-data"
data_file_name: "test_segments.csv"

# Debug configuration
debug_samples: -1 # Set to 0 or negative to use all samples, positive number to limit samples

